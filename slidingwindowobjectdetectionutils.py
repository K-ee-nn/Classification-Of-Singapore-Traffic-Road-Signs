# -*- coding: utf-8 -*-
"""slidingWindowObjectDetectionUtils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t5vGl33aB_unxQPmRmqiiYy_oY7sfbpH
"""

import cv2
import matplotlib.pyplot as plt
import numpy as np
import imutils
from imutils.object_detection import non_max_suppression
import time
import os
import pandas as pd
from tqdm import tqdm
import cv2 
import matplotlib.pyplot as plt
from matplotlib.image import imread

def sliding_window(image, step, ws):
    #slide a window of ws size over the image
    for y in range(0, image.shape[0]-ws[1]+1, step): # rows-wise loop
        # -ws[1] avoids extending the sliding window outside the image itself, increment the y-position with step
        for x in range(0, image.shape[1] - ws[0]+1, step):#columns-wise loop, increment the x-position with step
            # use yield(instead of return) because this is a generator
            #yield the actual x and y positions and the current window
            yield (x, y, image[y:y + ws[1], x:x + ws[0]])

def image_pyramid(image, scale=1.2, minSize=(150, 150)):
    # yield the original image, this is the base of the image pyramid
    yield image
    # keep looping over the image pyramid
    while True:
        # compute the dimensions of the next image in the pyramid
        #scale controls how much the image is resized at each layer
        w = int(image.shape[1] / scale)
        # resize the image and take care of image aspect-ratio
        image = imutils.resize(image, width=w) 
        # if the resized image does not meet the supplied minimum
        # size, then stop constructing the pyramid
        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:
            break
        # yield the next image in the pyramid
        yield image

def showROI(imagePath,WIDTH,WIN_STEP,ROI_SIZE):

  image=cv2.imread(imagePath)
  image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)
  image=imutils.resize(image, width=WIDTH)

  tmp = image # for drawing a rectangle
  stepSize = int(WIN_STEP)
  (w_width, w_height) = (int(ROI_SIZE[0]),int(ROI_SIZE[1])) # window size
  for x in range(0, image.shape[1] - w_width+1 , stepSize):
    for y in range(0, image.shape[0] - w_height+1, stepSize):
        window = image[x:x + w_width, y:y + w_height, :]
        cv2.rectangle(tmp, (x, y), (x + w_width, y + w_height), (255,0,0), 2) # draw rectangle on image
        plt.imshow(np.array(tmp).astype('uint8'))
  # show all windows
  plt.show()

def setUpROI(orig,WIN_STEP, PYR_SCALE, ROI_SIZE, INPUT_SIZE):
  H, W = orig.shape[:2] 
  print('Width:',W)
  pyramid = image_pyramid(orig, PYR_SCALE, ROI_SIZE)
  rois = []
  locs = []
  # time how long it takes to loop over the image pyramid layers and
  # sliding window locations
  start = time.time()
  counter = 0
  tot_images = 0
  for p, image in enumerate(pyramid):
      # determine the scale factor between the *original* image
      # dimensions and the *current* layer of the pyramid
      print('image :',image.shape)
      scale = W / float(image.shape[1])
      # for each layer of the image pyramid, loop over the sliding
      # window locations
      sw = 0
      for (x, y, roiOrig) in sliding_window(image, WIN_STEP, ROI_SIZE):
          #print(x,y)
          sw = sw + 1
          # scale the (x, y)-coordinates of the ROI with respect to the
          # *original* image dimensions
          
          #print('scale',scale)
          #print('before',x)
          x = int(x * scale)
          #print('after',x)
          y = int(y * scale)
          w = int(ROI_SIZE[0] * scale)
          h = int(ROI_SIZE[1] * scale)

          # take the ROI and pre-process it so we can later classify
          # the region using Keras/TensorFlow
          roi = cv2.resize(roiOrig,INPUT_SIZE,interpolation=cv2.INTER_AREA)
          roi=cv2.cvtColor(roi,cv2.COLOR_BGR2RGB)

          rois.append(roi)
          locs.append((x, y, x + w, y + h))

          tot_images = tot_images +1
  print(roiOrig.shape, roi.shape)
  # show how long it took to loop over the image pyramid layers and
  # sliding window locations
  end = time.time()
  print("[INFO] looping over pyramid/windows took {:.5f} seconds".format(end - start))
  print("Total images {:.2f}".format(tot_images))

  fig,(ax1,ax2,ax3)=plt.subplots(1,3)
  ax1.imshow(rois[7])

  ax2.imshow(rois[8])

  ax3.imshow(rois[9])

  return rois, locs

def classifyROI(rois, model):

  rois = np.array(rois, dtype="float32")
  print(rois.shape)
  # classify each of the proposal ROIs using trained classifier in PART 1, and then show how
  # long the classifications took.

  # Essentially, classify content of the window with your trained classifier and  
  # determine if the window includes a 'stop' or 'uturn' sign.

  print("[INFO] classifying ROIs...")
  start = time.time()
  my_preds = model.predict(rois)
  end = time.time()
  print("[INFO] classifying ROIs took {:.5f} seconds".format(end - start))
  return my_preds

def thresholdPrediction(my_preds,trialImage,threshold):

  ##write code to check if my_preds is below or above threshold. If below -> 'stop'.if above-> 'uturn'.
  threshold=threshold
  my_preds=my_preds
  preds=[]
  for each in my_preds:
    if each >=threshold:
      preds.append([(trialImage,'uturn',each)])
    
    elif each<threshold:
      preds.append([(trialImage,'stop',each)])
  print(preds)
  #print(np.array(preds))
  #print(my_preds)
  print(max(preds), min(preds),preds.index(max(preds)), preds.index(min(preds)))
  return preds

# labels (keys) to any ROIs associated with that label (values)
#preds = tf.keras.applications.imagenet_utils.decode_predictions(my_preds, top=1)

def createLabelsBoxesProb(preds,locs):
  labels = {}
  preds=preds
  #probs = {}
  # loop over the predictions
  for (i, p) in enumerate(preds):
      # grab the prediction information for the current ROI
      (imagenetID, label, prob) = p[0]
      #print(p)

      # filter out weak detections by ensuring the predicted probability
      # is greater than the minimum probability
      if prob>=0.8 or prob<=0.2:
      #if prob >= args["min_conf"]:
          # grab the bounding box associated with the prediction and
          # convert the coordinates
          box = locs[i]
          if prob<=0.5:
            prob=1-prob
          # grab the list of predictions for the label and add the
          # bounding box and probability to the list
          L = labels.get(label, [])
          L.append((box, prob))
          labels[label] = L
  print(labels)
  print(labels.keys())
  return labels

def objectDetection(orig,labels):
  trackProbability=[]

  allclone = orig.copy()
  for label in labels.keys():
      print(label)
     
      print("[INFO] showing results for '{}'".format(label))


      # extract the bounding boxes and associated prediction
      # probabilities, then apply non-maxima suppression
      boxes = np.array([p[0] for p in labels[label]])
      proba = np.array([p[1] for p in labels[label]])

  #Assume initial 'proba' for stop sign is less than 0.5. 
  #Therefore ,the more accurate the stop sign prediction, the smaller should be the 'proba' value.
  #'proba' value is logits output from sigmoid operation. And its range is between 0 and 1. 
  #Here, 'proba' value is taken as probability. 
  #The converse is true for uturn sign which should be as large towards 1 as possible. 
  #collect the max proba and box first. Then compare the two. Show only the larger box. 
      #proba=[1-p[1] if p[1]<0.5 else p[1] for p in labels[label] ]
      print(max(proba))
      
      boxes = non_max_suppression(boxes, proba, overlapThresh=0.5)

      #print(proba)
      print(boxes.shape)
      # loop over all bounding boxes that were kept after applying
      # non-maxima suppression

      trackProbability.extend(list(zip([p[1] for p in labels[label]],[label]*len(proba),[p[0] for p in labels[label]])))


  print('trackProbability before sort',trackProbability)
  trackProbability.sort(key=lambda y:y[0], reverse=True)
  print('trackProbability',trackProbability)
  
  #take only the top probabiity box and label.
  #[0][0] is prob
  #[0][1] is label
  #[0][2] is  boxes
  prob=trackProbability[0][0]

  label=trackProbability[0][1]
  print('highest prob label',label)

  #get class label of highest probability
  labelIndex=[ trackProbability.index(i) for i in trackProbability if i[1]==label]
  print('labelIndex',labelIndex)
  

  #select all same label as label with highest probability
  boxes= [trackProbability[i][2] for i in labelIndex]
  
  
  #clone the original image so that we can draw on it
  clone = orig.copy()

  #print(boxes, boxes.shape)
  #(startX, startY, endX, endY)=boxes[0]
  print(boxes)
  for (startX, startY, endX, endY) in boxes[0:10]:
    cv2.rectangle(clone, (startX, startY), (endX, endY),(255, 255, 0), 2)
    cv2.rectangle(allclone, (startX, startY), (endX, endY),(0, 255, 255), 2)
    y = startY - 50 if startY - 50 > 50 else startY + 50
    cv2.putText(clone, label, (startX, y+60),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    cv2.putText(clone, "{:.2f}".format(*(prob)), (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(allclone, label, (startX, y+60),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.putText(allclone, "{:.2f}".format(*(prob)), (startX, y+100),cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2) 



  plt.imshow(cv2.cvtColor(allclone,cv2.COLOR_BGR2RGB))

